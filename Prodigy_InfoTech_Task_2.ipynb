{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# import the libraries\n",
        "import random\n",
        "from collections import defaultdict\n",
        "import re"
      ],
      "metadata": {
        "id": "kiokbZ9ndNl6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MarkovChainTextGenerator:\n",
        "    def __init__(self, n=2):\n",
        "        \"\"\"\n",
        "        Initialize the Markov Chain Text Generator.\n",
        "\n",
        "        Parameters:\n",
        "        n (int): Size of the n-gram (e.g., n=2 → bigram model).\n",
        "\n",
        "        The model is stored as:\n",
        "            { (word1, word2): [next_possible_word1, next_possible_word2, ...] }\n",
        "        \"\"\"\n",
        "        self.n = n\n",
        "        self.model = defaultdict(list)\n",
        "\n",
        "    def preprocess(self, text):\n",
        "        \"\"\"\n",
        "        Convert text to lowercase and extract clean word tokens.\n",
        "\n",
        "        Returns:\n",
        "        List of words.\n",
        "        \"\"\"\n",
        "        # Lowercase entire text for consistency\n",
        "        text = text.lower()\n",
        "\n",
        "        # Extract only word characters (removes punctuation)\n",
        "        tokens = re.findall(r'\\b\\w+\\b', text)\n",
        "\n",
        "        return tokens\n",
        "\n",
        "    def train(self, text):\n",
        "        \"\"\"\n",
        "        Build the Markov chain model from the given input text.\n",
        "\n",
        "        - Breaks the text into n-grams (tuples)\n",
        "        - For each n-gram, stores the word that follows it\n",
        "        \"\"\"\n",
        "        tokens = self.preprocess(text)\n",
        "\n",
        "        # Iterate through tokens to form n-grams\n",
        "        for i in range(len(tokens) - self.n):\n",
        "            # Example: if n=2 → key = (tokens[i], tokens[i+1])\n",
        "            key = tuple(tokens[i : i + self.n])\n",
        "\n",
        "            # Next word after the n-gram\n",
        "            next_word = tokens[i + self.n]\n",
        "\n",
        "            # Store next word in the model\n",
        "            self.model[key].append(next_word)\n",
        "\n",
        "    def generate(self, max_words=50):\n",
        "        \"\"\"\n",
        "        Generate new text using the trained Markov chain.\n",
        "\n",
        "        Steps:\n",
        "        1. Pick a random starting n-gram.\n",
        "        2. Repeatedly lookup the next word from the model.\n",
        "        3. Stop if no continuation exists or max_words reached.\n",
        "\n",
        "        Returns:\n",
        "        A generated string of text.\n",
        "        \"\"\"\n",
        "\n",
        "        if not self.model:\n",
        "            raise ValueError(\"Model is empty. Please train it using train(text).\")\n",
        "\n",
        "        # Randomly choose a starting n-gram\n",
        "        start = random.choice(list(self.model.keys()))\n",
        "\n",
        "        # Initialize output list with the starting words\n",
        "        output = list(start)\n",
        "\n",
        "        # Generate remaining words\n",
        "        for _ in range(max_words - self.n):\n",
        "            # Take the last n words in output to form the current key\n",
        "            key = tuple(output[-self.n:])\n",
        "\n",
        "            # Get list of possible next words\n",
        "            next_words = self.model.get(key)\n",
        "\n",
        "            # If no continuation found, stop generation\n",
        "            if not next_words:\n",
        "                break\n",
        "\n",
        "            # Randomly choose the next word from candidates\n",
        "            next_word = random.choice(next_words)\n",
        "            output.append(next_word)\n",
        "\n",
        "        # Convert list of words back to a string\n",
        "        return ' '.join(output)\n"
      ],
      "metadata": {
        "id": "TQXUC_RZdnEP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = \"\"\"\n",
        "    A quick brown fox jumps over the lazy dog. The dog barked and chased the fox.\n",
        "    The fox ran into the forest and disappeared. The dog returned home tired but happy.\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "TOcU8QRVdqs2"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create generator with bigram (n=2) model\n",
        "generator = MarkovChainTextGenerator(n=2)"
      ],
      "metadata": {
        "id": "FbY9uQzJdtZu"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "generator.train(sample_text)"
      ],
      "metadata": {
        "id": "0pfp4_ZPdvZx"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate new text\n",
        "generated_text = generator.generate(max_words=30)"
      ],
      "metadata": {
        "id": "HCrtv-X4dxJd"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Generated Text:\\n\", generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2h9jHk2b9ek",
        "outputId": "e0b7d405-1e86-4ebe-bd66-0a3e090eee21"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text:\n",
            " the fox ran into the forest and disappeared the dog barked and chased the fox ran into the forest and disappeared the dog returned home tired but happy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rVnMPCEbcbyM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}